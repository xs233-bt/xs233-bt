## Hi there ğŸ‘‹ I'm Neo (Shunci) Lu  

ğŸ¯  **Data Engineer | Business Intelligence Analyst @ Scootaround Inc.**
  
ğŸ“ Based in Canada ğŸ‡¨ğŸ‡¦ | ğŸŒ Building scalable data pipelines & analytics solutions  

---

### ğŸ§  About Me  
- ğŸ”­ Iâ€™m currently working on **data engineering projects** involving Airflow, dbt, AWS (Glue, Redshift, Athena, S3), and open table formats like **Iceberg** and **Delta Lake**.  
- ğŸ§© Experienced in **data modeling**, **ETL/ELT automation**, and **financial analytics** (revenue, cost, margin reporting).  
- âš™ï¸ Skilled in **Python**, **SQL**, **Power BI**, **Spark**, and **Terraform** for building production-grade data pipelines.  
- ğŸš€ Passionate about transforming raw data into actionable insights and enabling self-serve analytics.  

---

### ğŸ—ï¸ Current Projects  

- **ğŸ“Š IBKR Real-Time Stock Data Streaming & Portfolio Monitoring**  
  Engineered a **real-time market data pipeline** leveraging the **IBKR API** and **Apache Kafka** to stream live quotes (e.g., TSLA, NVDA, AAPL).  
  Built **Python producers and consumers** to capture and process tick-level data, storing it efficiently in **AWS S3** for historical analysis.  
  Utilized **DuckDB** for fast local analytics and developed an interactive **Streamlit dashboard** to visualize portfolio performance, exposure, and trade signals in real time.  

- **ğŸ—ï¸ Modern Data Lakehouse with Apache Iceberg**  
  Designed and implemented a **schema-evolving data warehouse** on AWS using **S3 + Glue + Athena + Iceberg**, enabling versioned, ACID-compliant datasets.  
  Orchestrated **Airflow-based ingestion and transformation pipelines**, and modeled analytical layers using **dbt** and **Redshift Spectrum**.  
  Integrated **AWS Glue Data Quality** checks and **SQLMesh backfill automation** to maintain data accuracy, lineage, and reproducibility across the medallion architecture.  
 
- **ğŸ“§ Automated Airflow Reporting via SSH & SMTP**  
  Developed a **Python-based ETL pipeline** that securely connects to remote databases through **SSH tunneling**, extracts and transforms daily business data, and emails formatted reports to stakeholders.  
  The workflow was fully orchestrated using **Apache Airflow**, enabling scheduled automation, retry handling, and dependency tracking.  
  Technologies used include **pandas**, **sshtunnel**, **MySQL connector**, and **smtplib**, ensuring end-to-end automation without manual intervention.
---

### ğŸ§° Tech Stack & Tools  
**Languages:** Python, SQL, DAX, YAML, R, JAVA, Julia  
**Data Engineering:** Airflow | dbt | AWS Glue | Redshift | Athena | S3 | Terraform | Spark | Iceberg | Kafka | SQLMesh  
**Analytics:** Power BI | Tableau | pandas | DuckDB | Trino  
**Databases:** PostgreSQL | MySQL | SQL Server | Redshift Spectrum  
**Version Control & Infra:** GitHub | Docker | VS Code | Linux | AWS CLI  

---

### ğŸ“š Certifications & Learning  
- ğŸ“ **Data Engineering Professional Certificate** â€“ DeepLearning.AI  
- ğŸŒ©ï¸ Currently preparing for **AWS Certified Data Engineer â€“ Associate**  
- ğŸ§© Exploring advanced topics like **real-time Kafka streaming**, **SQLMesh backfill automation**, and **AI-assisted data ops**.  

---

### ğŸ’¬ Letâ€™s Connect  
ğŸ“« **Email:** [shunci233@gmail.com](mailto:neo.lu.data@gmail.com)  
ğŸ’¼ **LinkedIn:** [[linkedin.com/in/neolu](https://www.linkedin.com/in/neo-lu-4b10171a8/)](https://linkedin.com/in/neolu)  
ğŸ’» **GitHub:** [github.com/xs233-bt](https://github.com/xs233-bt)

---

### âš¡ Fun Fact  
Iâ€™ve been playing **Dota** for more than 10 years â€” mastering teamwork, strategy, and the art of not tilting under pressure ğŸ˜.  

---

> _â€œData without context is noise â€” my goal is to turn it into insight.â€_ ğŸš€
